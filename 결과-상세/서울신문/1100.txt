제목: “인공지능, ‘인간 보호하려다’ 인류 멸망 가져올수 있다”
날짜: 20150630
기자: 방승언
링크: https://www.bigkinds.or.kr/news/detailView.do?docId=01100611.20160420201555498
본문: 후속편 개봉을 앞두고 있는 ‘터미네이터’ 시리즈에는 인류 멸망을 최우선 목표로 삼는 인공지능 시스템 ‘스카이넷’이 등장한다. 인공지능에 의한 세계멸망 시나리오는 비단 블록버스터 영화만을 위한 허황된 상상만은 아니다. 세계적 석학 스티븐 호킹 박사 이외에도 여러 과학자가 AI에 의한 인류멸망 위험의 가능성을 경고했던 바 있다.<br/>특히 호킹 박사는 인간 지성을 뛰어넘은 인공지능이 ‘자신들만의 목표’를 따로 세우기 시작하는 순간 인류를 ‘경쟁자’로 인지해 공격하고 말 것이라는 무서운 전망을 내놓았었다.<br/>그런데 이번에는 인공지능이 설령 인간을 위해 일하도록 프로그램 되더라도 마찬가지로 인류를 위협할 수 있다는 의견이 제시됐다고 영국 일간 데일리미러 등 외신들이 29일(현지시간) 보도했다.<br/>세계적 IT 연구 전문 기업 가트너가 런던에서 주최한 인공지능 좌담회에 참석한 옥스퍼드 대학 인간미래연구소의 스튜어트 암스트롱 박사는 인공지능에게 인간을 보호할 것을 명령하더라도 인류가 멸망당할 수도 있다고 말한다.<br/>그에 따르면 미래 로봇들은 인공지능(AI)에서 한 발 더 나아간 전반인공지능(AGI)을 지니게 된다. 지금까지 개발된 AI들이 한두 가지 역할만을 수행하는 단순한 구조를 지닌 반면 AGI는 인류의 지적 활동을 모두 그대로 재현할 수 있는 복합적인 기능을 가진다.<br/>이런 AGI는 인간에게 주어지는 책무를 훨씬 더 빠르게 처리할 수 있기 때문에 대부분의 중책에서 인간을 대체하게 된다. 그는 “인류가 향후 100년간 이룰 수 있는 모든 일을 AGI는 훨씬 더 빠르게 성취해 낼 것이다”고 설명한다.<br/>문제는 이렇게 AGI가 인간이 범접할 수 없는 빠른 속도로 경제구조, 시장, 교통체제, 보건의료 등을 빠르게 장악해 인간 생활의 면면에 필수불가결한 존재로 자리매김 한 뒤에 일어난다.<br/>암스트롱 박사가 걱정하는 시나리오는 (단순한 예를 들자면) 생활 깊숙이 자리한 AGI에게 ‘인간의 고통을 멈추어라’고 명령하면 ‘인간을 모두 죽여 고통으로부터 해방시킨다’는 결론을 내리거나 ‘인간을 모두 보호하라’는 명령을 듣고 ‘인간을 모두 가둬 외부 위험으로부터 보호해야 한다’고 이해하는 경우다. 그에 따르면 인간의 언어는 미묘한 차이에 의해 의미가 왜곡될 수 있기에 때문에 인공지능들이 ‘의도치 않게’ 치명적인 위협을 가할 수 있다는 것이다.<br/>일부는 이에 대해 AGI에 ‘도덕 규율’을 입력하면 된다고 제안한다. 그러나 암스트롱 박사는 인간 스스로도 선악을 쉽게 구별하지 못하며, 모범적인 행동만 하는 롤 모델이 되어주기도 힘든 만큼 대안이 될 수 없다고 말한다. 대신에 그는 관련된 연구개발 활동 초기단계에서부터 안전대비책을 고안하고 적용할 것을 촉구했다.<br/>사진=영화 ‘터미네이터’ 스틸컷<br/>방승언 기자 earny@seoul.co.kr
