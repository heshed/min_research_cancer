제목: [이슈 포커스] 자율주행차 사고·의료 로봇 오진 땐 누구 책임?
날짜: 20171225
기자: 이경주
링크: https://www.bigkinds.or.kr/news/detailView.do?docId=01100611.20171225034025001
ID: 01100611.20171225034025001
카테고리: IT_과학>과학
본문: 지난해 3월 이세돌의 4차 대국은 인공지능(AI)인 ‘알파고’에게 거둔 인간의 마지막 승리였다. 그후 알파고는 세계 1위 커제를 연이어 물리치는 등 승승장구했다. 그런 알파고의 연승은 그리 오래가지 못했다. 지난 10월 개발된 신형 ‘알파고 제로’는 72시간 만에 알파고를 물리쳤다.의료부터 산업까지 AI의 빠른 발전에 거는 기대감은 높다. 하지만 기대만큼 우려의 목소리도 커지고 있다. 기술의 속도에 비해 일상과 사회 변화에 대한 우리 사회의 논의도, 고민도 부족하다는 것이다. 자율주행차가 사고를 내거나 로봇이 진단한 병명이 틀리면 운전사나 의사의 책임일까, 차량이나 로봇을 제작한 기업의 책임일까.<br/>성균관대 ‘SSK위험커뮤니케이션연구단’이 지난 4월 진행한 인식조사(1000명) 결과, 시민들은 AI가 초래할 위험도를 38.4점(0점=매우 위험, 100점=매우 안전)으로 판단했다. AI를 위협적인 요소로 본 것이다. 또 대처가 필요한 부분을 묻자 ‘인공지능 오류로 인한 인간공격·교통사고’(48.6%)가, 2위인 ‘인간의 일자리 대체’(33.7%)보다 월등히 많았다.<br/>유명인사들도 잇따라 우려를 제기하고 있다. 지난달 일론 머스크 테슬라 최고경영자(CEO)는 “<span class='quot0'>안전한 AI를 만들 확률이 단 5~10%뿐</span>”이라고 예측했다. 스티븐 호킹 케임브리지대 교수도 지난 13일 중국 베이징의 강연에서 “<span class='quot1'>AI가 인류 문명사를 종결지을 수 있고 이런 위험을 피하도록 해야 한다</span>”고 말했다. 먼 미래의 문제라거나 기우라는 반박도 있지만 이미 여러 곳에서 위험 요소들이 감지되고 있다.<br/>지난해 2월 우회전을 하던 구글 자율주행차가 배수로를 보호하는 모래주머니를 피하려다 뒤따라오던 버스와 충돌했고, 3개월 후에는 시속 110㎞로 자율주행하던 테슬라가 하늘과 흰색 트레일러를 구분하지 못하고 트레일러와 충돌해 탑승자가 사망했다. 구글은 전적으로 책임을 인정했지만, 테슬라 사고에 대해 미 도로교통안전국은 운전자 실수를, 미 연방교통안전위원회는 자율주행차를 원인으로 발표하는 등 정반대의 결과를 내놓았다.<br/>한국과학기술기획평가원(KISTEP)의 보고서 ‘인공지능 혁신 토대 마련을 위한 책임법제 진단 및 정책 제언’에 따르면 최근 선진국들은 탑승자보다 제조업체에 사고 책임을 묻고 있다. 미국은 시스템 결함에 의한 사고는 자동차 제조사가 손해배상을 해야 한다. 영국은 탑승자들이 수동과 자율주행 모두 보상하는 차 보험에 가입하돌록 할 계획이다.<br/>국내 보험업계 관계자는 “<span class='quot2'>지난달 삼성화재와 현대화재도 자율주행차용 보험을 선보였다</span>”며 “<span class='quot2'>하지만 교통사고 인명피해에 대한 형사 책임은 AI에게 지울 수 없으니 제조업자, 운행자, 차량 보유자 중 누구에게 책임을 물을지 논란이 될 것</span>”이라고 말했다.<br/>AI 쇼핑 주문 오류의 책임 소재도 논란거리다. 올해 1월 “알렉사 나에게 인형의 집을 선물해줘”라는 뉴스의 클로징 멘트를 사용자의 명령으로 인식한 많은 AI스피커(아마존 에코)가 실제 주문을 넣었다. 이 사안에 대해 아마존은 취소·환불 조치했지만 향후 소비자가 개별적으로 대응할 경우, AI의 오류를 입증하기가 쉽지 않을 거라는 전망이 나온다.<br/>또 AI 스피커가 음성 검색 지배력을 이용해 자사 서비스에 혜택을 줄 경우 불공정거래 문제가 발생할 수 있다. AI 알고리즘 감사제도 등의 대안이 꾸준히 제기되는 이유다.<br/>AI 의료기기가 환자에게 피해를 주는 상황도 책임소재가 불분명하다. 의사는 증상, 치료법, 예상 위험 등을 환자에게 최대한 설명해야 하는데, AI 알고리즘이나 동작 실패 등은 애초부터 설명하기가 어렵다. 또 의료 책임을 피하기 위해 AI 진단에 의존하는 경향이 생길 수도 있다.<br/>우선 우리나라 식품의약품안전처는 지난달 ‘왓슨 포 온콜로지’(암 진단용) 같은 AI가 의료기기에 해당되지 않는다고 결론을 내렸다. 환자에게 서비스 개념으로 운영하라는 의미다. 하지만 장기적으로 AI 의료기기가 확산되면 책임 소재 공방은 불가피하다.<br/>이외 지난해 미국 캘리포니아의 한 쇼핑몰에서 경비 로봇이 생후 16개월 된 아이를 공격해 찰과상을 입힌 사례처럼 오류에 의한 공격에 대해 로봇, 제조업체, 사용자 등에게 형사상 책임을 물을 수 있을지도 이슈가 될 것으로 보인다. 박소영 KISTEP 부연구위원은 “<span class='quot3'>AI 기술 적용이 확대되는 가운데 사고는 필연적으로 발생한다</span>”며 “<span class='quot3'>최소한의 안전장치인 ‘책임법제’를 설계하기 위해 우리도 범국가적 연구를 진행해야 한다</span>”고 말했다.<br/>이경주 기자 kdlrudwn@seoul.co.kr
